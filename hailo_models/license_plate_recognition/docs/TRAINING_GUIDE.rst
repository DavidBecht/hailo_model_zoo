Train License Plate Recognition on a Custom Dataset
---------------------------------------------------

Here we describe how to finetune Hailo's optical character reader (OCR) model for license plate recognition with your own custom dataset.

Prerequisites
^^^^^^^^^^^^^


* docker (\ `installation instructions <https://docs.docker.com/engine/install/ubuntu/>`_\ )
* nvidia-docker2 (\ `installation instructions <https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html>`_\ )


**NOTE:**  In case you are using the Hailo Software Suite docker, make sure to run all of the following instructions outside of that docker.


Environment Preparations
^^^^^^^^^^^^^^^^^^^^^^^^


#. 
   **Build the docker image**

   .. raw:: html
      :name:validation

      <code stage="docker_build">
      cd <span val="dockerfile_path">hailo_model_zoo/hailo_models/license_plate_recognition/</span>

      docker build  --build-arg timezone=\`cat /etc/timezone\` -t license_plate_recognition:v0 .
      </code>

   * This command will build the docker image with the necessary requirements using the Dockerfile that exists in this directory.

#. 
   **Start your docker:**

   .. raw:: html
      :name:validation

      <code stage="docker_run">
      docker run <span val="replace_none">--name "your_docker_name"</span> -it --gpus all --ipc=host -v <span val="local_vol_path">/path/to/local/data/dir</span>:<span val="docker_vol_path">/path/to/docker/data/dir</span> license_plate_recognition:v0
      </code>


   * ``docker run`` create a new docker container.
   * ``--name <your_docker_name>`` name for your container.
   * ``-it`` runs the command interactively.
   * ``--gpus all`` allows access to all GPUs.
   * ``--ipc=host`` sets the IPC mode for the container.
   * ``-v /path/to/local/data/dir:/path/to/docker/data/dir`` maps ``/path/to/local/data/dir`` from the host to the container. You can use this command multiple times to mount multiple directories.
   * ``license_plate_recognition:v0`` the name of the docker image.

Finetuning and exporting to ONNX
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


#. 
   | **Train the network on your dataset**
   | Once the docker is started, you can train the OCR on your custom dataset.


   * Create a folder with license plates images for training and testing. The folder should contain images whose file names correspond to the plate number, e.g. ``12345678.png``.


   **NOTE:**  Please make sure the file names **do not** contain characters which are not numbers or letters.


   * 
     Alternatively, you can use the provided jupyter notebook in ``dataset/lp_autogenerate.ipynb`` as an example of how to auto-generate a synthetic dataset of license plates for training. The auto-generation uses several parameters to control the randomness in the dataset, such as allowed characters, font size, font color, character separation etc. (Please refer to the notebook for more details). In order to auto-generate the synthetic dataset, please provide the following:


     * Clean license plate images with no characters in the  ``dataset/plates/`` folder
     * ``.ttf`` font files in the ``dataset/fonts/`` folder

   **NOTE:**  We recommend the autogenerated training set to contain at least 4 million images

   * 
     Start training on your dataset:


     * Start from our pre-trained weights in ``pre_trained/lprnet.pth`` (you can also download it from `here <https://hailo-model-zoo.s3.eu-west-2.amazonaws.com/HailoNets/LPR/ocr/lprnet/2022-03-09/lprnet.pth>`_\ )
  
       .. raw:: html
          :name:validation

          <code stage="retrain">
          python train_LPRNet.py --train_img_dirs <span val="docker_vol_path">path/to/train/images</span> --test_img_dirs <span val="docker_vol_path">path/to/test/images</span> --max_epoch <span val="epochs">30</span> --train_batch_size <span val="batch_size">64</span> --test_batch_size <span val="batch_size">32</span> --resume_epoch 15 --pretrained_model pre_trained/lprnet.pth --save_folder runs/exp0/ --test_interval <span val="batch_size">2000</span>
          </code>

     * Or train from scratch

       .. code-block::

         python train_LPRNet.py --train_img_dirs path/to/train/images --test_img_dirs path/to/test/images --max_epoch 15 --save_folder runs/exp0/

#. | **Export to ONNX**
   | Export the model to ONNX using the following command:

   .. raw:: html
      :name:validation

      <code stage="export">
      python export.py --onnx lprnet.onnx --weights <span val="docker_trained_path">/path/to/trained/model.pth</span>
      </code>

----

Compile the Model using Hailo Model Zoo
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

You can generate an HEF file for inference on Hailo-8 from your trained ONNX model. In order to do so you need a working model-zoo environment.
Choose the model YAML from our networks configuration directory, i.e. ``hailo_model_zoo/cfg/networks/lprnet.yaml``\ , and run compilation using the model zoo:

.. raw:: html
   :name:validation

   <code stage="compile">
   hailomz compile --ckpt <span val="local_path_to_onnx">lprnet.onnx</span> --calib-path <span val="calib_set_path">/path/to/calibration/imgs/dir/</span> --yaml <span val="yaml_file_path">lprnet.yaml</span>
   </code>

* ``--ckpt`` - path to your ONNX file.
* ``--calib-path`` - path to a directory with your calibration images in JPEG/PNG format
* ``--yaml`` - path to your configuration YAML file.

The model zoo will take care of adding the input normalization to be part of the model.
