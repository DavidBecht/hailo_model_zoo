normalization1 = normalization([119.85, 113.985, 104.04], [70.89, 69.87, 73.695])
model_optimization_config(calibration, batch_size=8, calibset_size=2048)
# post_quantization_optimization commands
post_quantization_optimization(finetune, policy=enabled, loss_factors=[1.0, 0.25, 0.25, 0.25, 0.25, 0.25], dataset_size=4000, epochs=8, learning_rate=0.0001, loss_types=[l2, l2, l2, l2, l2, l2])
quantization_param(output_layer1, precision_mode=a16_w16)
